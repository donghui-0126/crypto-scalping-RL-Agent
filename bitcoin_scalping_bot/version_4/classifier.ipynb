{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import torchsummary\n",
    "\n",
    "\n",
    "with open('C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\crypto-scalping-RL-Agent\\\\data\\\\df_final.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>mid_price</th>\n",
       "      <th>log_returns</th>\n",
       "      <th>7min_MA</th>\n",
       "      <th>25min_MA</th>\n",
       "      <th>99min_MA</th>\n",
       "      <th>300min_MA</th>\n",
       "      <th>900min_MA</th>\n",
       "      <th>7_ema</th>\n",
       "      <th>25_ema</th>\n",
       "      <th>...</th>\n",
       "      <th>log_99_ema</th>\n",
       "      <th>log_300_ema</th>\n",
       "      <th>log_900_ema</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>obv</th>\n",
       "      <th>rsi</th>\n",
       "      <th>vma</th>\n",
       "      <th>vol_pct</th>\n",
       "      <th>MACD-SIGNAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:17:00</th>\n",
       "      <td>0.047696</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>3.640008</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>-2.819888e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-32.190122</td>\n",
       "      <td>-42.986946</td>\n",
       "      <td>-0.023471</td>\n",
       "      <td>0.427829</td>\n",
       "      <td>-0.003950</td>\n",
       "      <td>-1.147692</td>\n",
       "      <td>10.796824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:18:00</th>\n",
       "      <td>0.751147</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>-0.718221</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>-3.393075e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-27.518817</td>\n",
       "      <td>-39.893321</td>\n",
       "      <td>-0.009338</td>\n",
       "      <td>0.437425</td>\n",
       "      <td>0.011163</td>\n",
       "      <td>14.748759</td>\n",
       "      <td>12.374503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:19:00</th>\n",
       "      <td>-0.154670</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>1.388568</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>5.096603e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-22.633165</td>\n",
       "      <td>-36.441289</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.524746</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>-1.205912</td>\n",
       "      <td>13.808125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:20:00</th>\n",
       "      <td>-0.342243</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-1.312561</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>3.013098e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-18.832632</td>\n",
       "      <td>-32.919558</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.623181</td>\n",
       "      <td>-0.027872</td>\n",
       "      <td>1.212726</td>\n",
       "      <td>14.086926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:21:00</th>\n",
       "      <td>0.387552</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>0.636838</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.387157e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-16.107056</td>\n",
       "      <td>-29.557057</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>0.639589</td>\n",
       "      <td>-0.003525</td>\n",
       "      <td>-2.132388</td>\n",
       "      <td>13.450002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       volume  mid_price  log_returns   7min_MA  25min_MA   \n",
       "time                                                                        \n",
       "2022-11-14 20:17:00  0.047696   0.001045     3.640008  0.000262 -0.000404  \\\n",
       "2022-11-14 20:18:00  0.751147   0.000294    -0.718221  0.000422 -0.000253   \n",
       "2022-11-14 20:19:00 -0.154670   0.000703     1.388568  0.000675 -0.000139   \n",
       "2022-11-14 20:20:00 -0.342243  -0.000220    -1.312561  0.000625  0.000014   \n",
       "2022-11-14 20:21:00  0.387552  -0.000360     0.636838  0.000498  0.000163   \n",
       "\n",
       "                     99min_MA  300min_MA  900min_MA     7_ema        25_ema   \n",
       "time                                                                          \n",
       "2022-11-14 20:17:00 -0.000231  -0.000075    0.00002  0.000513 -2.819888e-05  \\\n",
       "2022-11-14 20:18:00 -0.000242  -0.000069    0.00002  0.000459 -3.393075e-06   \n",
       "2022-11-14 20:19:00 -0.000222  -0.000065    0.00002  0.000520  5.096603e-05   \n",
       "2022-11-14 20:20:00 -0.000220  -0.000063    0.00002  0.000335  3.013098e-05   \n",
       "2022-11-14 20:21:00 -0.000224  -0.000061    0.00002  0.000161  1.387157e-07   \n",
       "\n",
       "                     ...  log_99_ema  log_300_ema  log_900_ema       MACD   \n",
       "time                 ...                                                    \n",
       "2022-11-14 20:17:00  ...   -0.000190    -0.000101    -0.000052 -32.190122  \\\n",
       "2022-11-14 20:18:00  ...   -0.000180    -0.000098    -0.000051 -27.518817   \n",
       "2022-11-14 20:19:00  ...   -0.000160    -0.000093    -0.000050 -22.633165   \n",
       "2022-11-14 20:20:00  ...   -0.000162    -0.000094    -0.000050 -18.832632   \n",
       "2022-11-14 20:21:00  ...   -0.000166    -0.000096    -0.000051 -16.107056   \n",
       "\n",
       "                     Signal_Line       obv       rsi       vma    vol_pct   \n",
       "time                                                                        \n",
       "2022-11-14 20:17:00   -42.986946 -0.023471  0.427829 -0.003950  -1.147692  \\\n",
       "2022-11-14 20:18:00   -39.893321 -0.009338  0.437425  0.011163  14.748759   \n",
       "2022-11-14 20:19:00   -36.441289  0.002610  0.524746  0.003284  -1.205912   \n",
       "2022-11-14 20:20:00   -32.919558  0.010468  0.623181 -0.027872   1.212726   \n",
       "2022-11-14 20:21:00   -29.557057 -0.000436  0.639589 -0.003525  -2.132388   \n",
       "\n",
       "                     MACD-SIGNAL  \n",
       "time                              \n",
       "2022-11-14 20:17:00    10.796824  \n",
       "2022-11-14 20:18:00    12.374503  \n",
       "2022-11-14 20:19:00    13.808125  \n",
       "2022-11-14 20:20:00    14.086926  \n",
       "2022-11-14 20:21:00    13.450002  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mid_price\n",
       "2    210659\n",
       "0    209904\n",
       "1    103552\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.00005\n",
    "target = pd.cut(df['mid_price'], bins=[-float('inf'), -threshold, threshold, float('inf')], labels=[0, 1, 2])\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524052/524052 [00:02<00:00, 216097.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524052, 30, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "feature = df\n",
    "\n",
    "# 주어진 데이터프레임\n",
    "sequence_length = 64\n",
    "n_samples = len(df) - sequence_length + 1\n",
    "\n",
    "# Extract the data as a NumPy array\n",
    "data_array = df.to_numpy()\n",
    "\n",
    "# Create an empty array to store the input sequences\n",
    "input_sequences = np.empty((n_samples, (df.shape[1]), sequence_length))\n",
    "\n",
    "for i in tqdm(range(n_samples)):\n",
    "    input_seq = data_array[i:i + sequence_length, :].T  # Transpose to have (24, 60) shape\n",
    "    input_sequences[i] = input_seq\n",
    "\n",
    "print(input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((524051, 30, 64), (524051,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = input_sequences[:-1]\n",
    "y = target.shift(-1)[63:].dropna()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 30, 64) (100000,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# 피처와 타겟 데이터 생성 (예시 데이터)\n",
    "num_samples = 524052\n",
    "num_channels = 1\n",
    "num_classes = 3\n",
    "\n",
    "feature = np.array(X[-100000:], dtype=np.float32)\n",
    "target = np.array(y[-100000:], dtype=np.float32)\n",
    "\n",
    "print(feature.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading...\n",
      "optimizer loading...\n"
     ]
    }
   ],
   "source": [
    "from classifier import Classifier \n",
    "\n",
    "dataset = TensorDataset(torch.tensor(feature, dtype=torch.float32), torch.tensor(target, dtype=torch.int64))\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "print(\"model loading...\")\n",
    "# 모델 초기화\n",
    "classifier_model = Classifier(input_channels=num_channels, num_classes=3)\n",
    "\n",
    "print(\"optimizer loading...\")\n",
    "# 손실 함수 및 최적화기 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.Adam(classifier_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.0570, Accuracy: 41.38%\n",
      "Epoch [2/100], Loss: 1.0533, Accuracy: 42.13%\n",
      "Epoch [3/100], Loss: 1.0504, Accuracy: 41.94%\n",
      "Epoch [4/100], Loss: 1.0481, Accuracy: 42.71%\n",
      "Epoch [5/100], Loss: 1.0460, Accuracy: 43.51%\n",
      "Epoch [6/100], Loss: 1.0441, Accuracy: 44.07%\n",
      "Epoch [7/100], Loss: 1.0440, Accuracy: 43.97%\n",
      "Epoch [8/100], Loss: 1.0431, Accuracy: 44.41%\n",
      "Epoch [9/100], Loss: 1.0423, Accuracy: 44.64%\n",
      "Epoch [10/100], Loss: 1.0401, Accuracy: 45.05%\n",
      "Epoch [11/100], Loss: 1.0385, Accuracy: 45.57%\n",
      "Epoch [12/100], Loss: 1.0364, Accuracy: 46.00%\n",
      "Epoch [13/100], Loss: 1.0347, Accuracy: 46.42%\n",
      "Epoch [14/100], Loss: 1.0341, Accuracy: 46.65%\n",
      "Epoch [15/100], Loss: 1.0314, Accuracy: 47.09%\n",
      "Epoch [16/100], Loss: 1.0285, Accuracy: 47.75%\n",
      "Epoch [17/100], Loss: 1.0257, Accuracy: 48.29%\n",
      "Epoch [18/100], Loss: 1.0219, Accuracy: 48.95%\n",
      "Epoch [19/100], Loss: 1.0179, Accuracy: 49.61%\n",
      "Epoch [20/100], Loss: 1.0155, Accuracy: 49.98%\n",
      "Epoch [21/100], Loss: 1.0100, Accuracy: 51.03%\n",
      "Epoch [22/100], Loss: 1.0059, Accuracy: 51.59%\n",
      "Epoch [23/100], Loss: 1.0011, Accuracy: 52.20%\n",
      "Epoch [24/100], Loss: 0.9952, Accuracy: 53.08%\n",
      "Epoch [25/100], Loss: 0.9901, Accuracy: 53.74%\n",
      "Epoch [26/100], Loss: 0.9867, Accuracy: 54.23%\n",
      "Epoch [27/100], Loss: 0.9823, Accuracy: 54.77%\n",
      "Epoch [28/100], Loss: 0.9755, Accuracy: 55.72%\n",
      "Epoch [29/100], Loss: 0.9728, Accuracy: 56.22%\n",
      "Epoch [30/100], Loss: 0.9703, Accuracy: 56.51%\n",
      "Epoch [31/100], Loss: 0.9656, Accuracy: 57.03%\n",
      "Epoch [32/100], Loss: 0.9618, Accuracy: 57.44%\n",
      "Epoch [33/100], Loss: 0.9577, Accuracy: 57.94%\n",
      "Epoch [34/100], Loss: 0.9533, Accuracy: 58.39%\n",
      "Epoch [35/100], Loss: 0.9516, Accuracy: 58.65%\n",
      "Epoch [36/100], Loss: 0.9503, Accuracy: 58.84%\n",
      "Epoch [37/100], Loss: 0.9501, Accuracy: 58.79%\n",
      "Epoch [38/100], Loss: 0.9452, Accuracy: 59.45%\n",
      "Epoch [39/100], Loss: 0.9424, Accuracy: 59.80%\n",
      "Epoch [40/100], Loss: 0.9351, Accuracy: 60.62%\n",
      "Epoch [41/100], Loss: 0.9303, Accuracy: 61.19%\n",
      "Epoch [42/100], Loss: 0.9285, Accuracy: 61.45%\n",
      "Epoch [43/100], Loss: 0.9241, Accuracy: 61.93%\n",
      "Epoch [44/100], Loss: 0.9245, Accuracy: 61.88%\n",
      "Epoch [45/100], Loss: 0.9225, Accuracy: 62.02%\n",
      "Epoch [46/100], Loss: 0.9180, Accuracy: 62.63%\n",
      "Epoch [47/100], Loss: 0.9167, Accuracy: 62.78%\n",
      "Epoch [48/100], Loss: 0.9158, Accuracy: 62.75%\n",
      "Epoch [49/100], Loss: 0.9153, Accuracy: 62.87%\n",
      "Epoch [50/100], Loss: 0.9158, Accuracy: 62.71%\n",
      "Epoch [51/100], Loss: 0.9128, Accuracy: 63.03%\n",
      "Epoch [52/100], Loss: 0.9130, Accuracy: 63.03%\n",
      "Epoch [53/100], Loss: 0.9113, Accuracy: 63.24%\n",
      "Epoch [54/100], Loss: 0.9103, Accuracy: 63.37%\n",
      "Epoch [55/100], Loss: 0.9116, Accuracy: 63.12%\n",
      "Epoch [56/100], Loss: 0.9125, Accuracy: 63.09%\n",
      "Epoch [57/100], Loss: 0.9064, Accuracy: 63.78%\n",
      "Epoch [58/100], Loss: 0.9032, Accuracy: 64.14%\n",
      "Epoch [59/100], Loss: 0.8980, Accuracy: 64.69%\n",
      "Epoch [60/100], Loss: 0.8939, Accuracy: 65.11%\n",
      "Epoch [61/100], Loss: 0.8912, Accuracy: 65.41%\n",
      "Epoch [62/100], Loss: 0.8886, Accuracy: 65.71%\n",
      "Epoch [63/100], Loss: 0.8882, Accuracy: 65.75%\n",
      "Epoch [64/100], Loss: 0.8826, Accuracy: 66.39%\n",
      "Epoch [65/100], Loss: 0.8826, Accuracy: 66.37%\n",
      "Epoch [66/100], Loss: 0.8807, Accuracy: 66.55%\n",
      "Epoch [67/100], Loss: 0.8818, Accuracy: 66.45%\n",
      "Epoch [68/100], Loss: 0.8774, Accuracy: 66.90%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 역전파 및 가중치 갱신\u001b[39;00m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     22\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # 모델 예측\n",
    "        outputs = classifier_model(inputs)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 역전파 및 가중치 갱신\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # 에폭마다 평균 손실 및 정확도 출력\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier_model, \"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\crypto-scalping-RL-Agent\\\\bitcoin_scalping_bot\\\\version_4\\\\classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint= torch.load(\"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\crypto-scalping-RL-Agent\\\\bitcoin_scalping_bot\\\\version_4\\\\classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv2d_1): Conv2d(1, 8, kernel_size=(12, 2), stride=(12, 2))\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2d_2): Conv2d(8, 16, kernel_size=(1, 17), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2d_3): Conv2d(16, 32, kernel_size=(1, 9), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm1): LSTM(512, 64)\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
