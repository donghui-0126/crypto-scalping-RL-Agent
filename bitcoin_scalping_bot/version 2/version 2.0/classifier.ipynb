{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "from torchsummary import summary \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "with open('C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\crypto-scalping-RL-Agent\\\\data\\\\df_final.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>mid_price</th>\n",
       "      <th>log_returns</th>\n",
       "      <th>7min_MA</th>\n",
       "      <th>25min_MA</th>\n",
       "      <th>99min_MA</th>\n",
       "      <th>300min_MA</th>\n",
       "      <th>900min_MA</th>\n",
       "      <th>7_ema</th>\n",
       "      <th>25_ema</th>\n",
       "      <th>...</th>\n",
       "      <th>log_99_ema</th>\n",
       "      <th>log_300_ema</th>\n",
       "      <th>log_900_ema</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal_Line</th>\n",
       "      <th>obv</th>\n",
       "      <th>rsi</th>\n",
       "      <th>vma</th>\n",
       "      <th>vol_pct</th>\n",
       "      <th>MACD-SIGNAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:17:00</th>\n",
       "      <td>0.047696</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>3.640008</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>-2.819888e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-32.190122</td>\n",
       "      <td>-42.986946</td>\n",
       "      <td>-0.023471</td>\n",
       "      <td>0.427829</td>\n",
       "      <td>-0.003950</td>\n",
       "      <td>-1.147692</td>\n",
       "      <td>10.796824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:18:00</th>\n",
       "      <td>0.751147</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>-0.718221</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>-3.393075e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-27.518817</td>\n",
       "      <td>-39.893321</td>\n",
       "      <td>-0.009338</td>\n",
       "      <td>0.437425</td>\n",
       "      <td>0.011163</td>\n",
       "      <td>14.748759</td>\n",
       "      <td>12.374503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:19:00</th>\n",
       "      <td>-0.154670</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>1.388568</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>5.096603e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-22.633165</td>\n",
       "      <td>-36.441289</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.524746</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>-1.205912</td>\n",
       "      <td>13.808125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:20:00</th>\n",
       "      <td>-0.342243</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-1.312561</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>3.013098e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-18.832632</td>\n",
       "      <td>-32.919558</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.623181</td>\n",
       "      <td>-0.027872</td>\n",
       "      <td>1.212726</td>\n",
       "      <td>14.086926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 20:21:00</th>\n",
       "      <td>0.387552</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>0.636838</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>1.387157e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-16.107056</td>\n",
       "      <td>-29.557057</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>0.639589</td>\n",
       "      <td>-0.003525</td>\n",
       "      <td>-2.132388</td>\n",
       "      <td>13.450002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       volume  mid_price  log_returns   7min_MA  25min_MA  \\\n",
       "time                                                                        \n",
       "2022-11-14 20:17:00  0.047696   0.001045     3.640008  0.000262 -0.000404   \n",
       "2022-11-14 20:18:00  0.751147   0.000294    -0.718221  0.000422 -0.000253   \n",
       "2022-11-14 20:19:00 -0.154670   0.000703     1.388568  0.000675 -0.000139   \n",
       "2022-11-14 20:20:00 -0.342243  -0.000220    -1.312561  0.000625  0.000014   \n",
       "2022-11-14 20:21:00  0.387552  -0.000360     0.636838  0.000498  0.000163   \n",
       "\n",
       "                     99min_MA  300min_MA  900min_MA     7_ema        25_ema  \\\n",
       "time                                                                          \n",
       "2022-11-14 20:17:00 -0.000231  -0.000075    0.00002  0.000513 -2.819888e-05   \n",
       "2022-11-14 20:18:00 -0.000242  -0.000069    0.00002  0.000459 -3.393075e-06   \n",
       "2022-11-14 20:19:00 -0.000222  -0.000065    0.00002  0.000520  5.096603e-05   \n",
       "2022-11-14 20:20:00 -0.000220  -0.000063    0.00002  0.000335  3.013098e-05   \n",
       "2022-11-14 20:21:00 -0.000224  -0.000061    0.00002  0.000161  1.387157e-07   \n",
       "\n",
       "                     ...  log_99_ema  log_300_ema  log_900_ema       MACD  \\\n",
       "time                 ...                                                    \n",
       "2022-11-14 20:17:00  ...   -0.000190    -0.000101    -0.000052 -32.190122   \n",
       "2022-11-14 20:18:00  ...   -0.000180    -0.000098    -0.000051 -27.518817   \n",
       "2022-11-14 20:19:00  ...   -0.000160    -0.000093    -0.000050 -22.633165   \n",
       "2022-11-14 20:20:00  ...   -0.000162    -0.000094    -0.000050 -18.832632   \n",
       "2022-11-14 20:21:00  ...   -0.000166    -0.000096    -0.000051 -16.107056   \n",
       "\n",
       "                     Signal_Line       obv       rsi       vma    vol_pct  \\\n",
       "time                                                                        \n",
       "2022-11-14 20:17:00   -42.986946 -0.023471  0.427829 -0.003950  -1.147692   \n",
       "2022-11-14 20:18:00   -39.893321 -0.009338  0.437425  0.011163  14.748759   \n",
       "2022-11-14 20:19:00   -36.441289  0.002610  0.524746  0.003284  -1.205912   \n",
       "2022-11-14 20:20:00   -32.919558  0.010468  0.623181 -0.027872   1.212726   \n",
       "2022-11-14 20:21:00   -29.557057 -0.000436  0.639589 -0.003525  -2.132388   \n",
       "\n",
       "                     MACD-SIGNAL  \n",
       "time                              \n",
       "2022-11-14 20:17:00    10.796824  \n",
       "2022-11-14 20:18:00    12.374503  \n",
       "2022-11-14 20:19:00    13.808125  \n",
       "2022-11-14 20:20:00    14.086926  \n",
       "2022-11-14 20:21:00    13.450002  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    210659\n",
       "0    209904\n",
       "1    103552\n",
       "Name: mid_price, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.00005\n",
    "target = pd.cut(df['mid_price'], bins=[-float('inf'), -threshold, threshold, float('inf')], labels=[0, 1, 2])\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/524052 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524052/524052 [00:03<00:00, 161353.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524052, 30, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feature = df\n",
    "\n",
    "# 주어진 데이터프레임\n",
    "sequence_length = 64\n",
    "n_samples = len(df) - sequence_length + 1\n",
    "\n",
    "# Extract the data as a NumPy array\n",
    "data_array = df.to_numpy()\n",
    "\n",
    "# Create an empty array to store the input sequences\n",
    "input_sequences = np.empty((n_samples, (df.shape[1]), sequence_length))\n",
    "\n",
    "for i in tqdm(range(n_samples)):\n",
    "    input_seq = data_array[i:i + sequence_length, :].T  # Transpose to have (24, 60) shape\n",
    "    input_sequences[i] = input_seq\n",
    "\n",
    "print(input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((524051, 30, 64), (524051,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = input_sequences[:-1]\n",
    "y = target.shift(-1)[63:].dropna()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 30, 64) (100000,)\n"
     ]
    }
   ],
   "source": [
    "# 피처와 타겟 데이터 생성 (예시 데이터)\n",
    "num_samples = 524052\n",
    "num_channels = 1\n",
    "num_classes = 3\n",
    "\n",
    "feature = np.array(X[-100000:], dtype=np.float32)\n",
    "target = np.array(y[-100000:], dtype=np.float32)\n",
    "\n",
    "print(feature.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading...\n",
      "optimizer loading...\n"
     ]
    }
   ],
   "source": [
    "from classifier import Classifier \n",
    "\n",
    "dataset = TensorDataset(torch.tensor(feature, dtype=torch.float32), torch.tensor(target, dtype=torch.int64))\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "print(\"model loading...\")\n",
    "# 모델 초기화\n",
    "classifier_model = Classifier(input_channels=num_channels, num_classes=3)\n",
    "\n",
    "print(\"optimizer loading...\")\n",
    "# 손실 함수 및 최적화기 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.Adam(classifier_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 모델 예측\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m classifier_model(inputs)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 손실 계산\u001b[39;00m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\Documents\\GitHub\\crypto-scalping-RL-Agent\\bitcoin_scalping_bot\\version_4\\classifier.py:40\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Assuming x has shape (batch_size, channels, height, width)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm1(x)\n\u001b[0;32m     41\u001b[0m lstm_out \u001b[38;5;241m=\u001b[39m lstm_out[:, :]  \u001b[38;5;66;03m# Take the last time step's output\u001b[39;00m\n\u001b[0;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(lstm_out))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # 모델 예측\n",
    "        outputs = classifier_model(inputs)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 역전파 및 가중치 갱신\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # 에폭마다 평균 손실 및 정확도 출력\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(classifier_model, \"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\crypto-scalping-RL-Agent\\\\bitcoin_scalping_bot\\\\version_4\\\\classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"C:\\\\Users\\\\user\\\\Documents\\\\GitHub\\\\crypto-scalping-RL-Agent\\\\bitcoin_scalping_bot\\\\version_4\\\\classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d_1:\n",
      "Conv2d(1, 8, kernel_size=(12, 2), stride=(12, 2))\n",
      "\n",
      "Conv2d_2:\n",
      "Conv2d(8, 16, kernel_size=(1, 17), stride=(1, 1))\n",
      "\n",
      "Conv2d_3:\n",
      "Conv2d(16, 32, kernel_size=(1, 9), stride=(1, 1))\n",
      "\n",
      "FC1:\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "\n",
      "FC2:\n",
      "Linear(in_features=32, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Print summary for Conv2d layers\n",
    "print(\"Conv2d_1:\")\n",
    "print(model.conv2d_1)\n",
    "print(\"\\nConv2d_2:\")\n",
    "print(model.conv2d_2)\n",
    "print(\"\\nConv2d_3:\")\n",
    "print(model.conv2d_3)\n",
    "\n",
    "# Print summary for Linear layers\n",
    "print(\"\\nFC1:\")\n",
    "print(model.fc1)\n",
    "print(\"\\nFC2:\")\n",
    "print(model.fc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv2d_1): Conv2d(1, 8, kernel_size=(12, 2), stride=(12, 2))\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2d_2): Conv2d(8, 16, kernel_size=(1, 17), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2d_3): Conv2d(16, 32, kernel_size=(1, 9), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm1): LSTM(512, 64)\n",
       "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
